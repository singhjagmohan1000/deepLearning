{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Dataset",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhjagmohan1000/deepLearning/blob/master/Fashion_MNIST_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "aj9VQY2G8Ra8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "gt2HIUl_7v4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "6b495ba2-4235-406b-efe7-5a767fb166bd"
      },
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow_datasets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/b8/457ad44e8748fbe5021b4ca7e7d589b5852881bbb11bca4d947952a13558/tensorflow_datasets-1.0.1-py3-none-any.whl (400kB)\n",
            "\u001b[K    100% |████████████████████████████████| 409kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.10.11)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.13.0)\n",
            "Requirement already satisfied, skipping upgrade: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (3.7.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tensorflow_datasets) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tensorflow_datasets) (2019.3.9)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tensorflow_datasets) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.5.8)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow_datasets) (40.8.0)\n",
            "Installing collected packages: tensorflow-datasets\n",
            "Successfully installed tensorflow-datasets-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jFBgGDF_8jiE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b66cbda1-4c8d-4f7d-d139-8e84b0fa28f9"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tf_dataset\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E_PT03EC81wE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3828
        },
        "outputId": "8e3f79f4-5431-404e-a6c1-6398ddb861f7"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dataset, metadata = tf_dataset.load('fashion_mnist', as_supervised=True, with_info=True)\n",
        "training_dataset, testing_dataset = dataset['train'], dataset['test']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading / extracting dataset fashion_mnist (29.45 MiB) to /root/tensorflow_datasets/fashion_mnist/1.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
            "Dl Size...:   0%|          | 0/25 [00:00<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
            "Dl Size...:   0%|          | 0/25 [00:00<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  2.64 url/s]\n",
            "Dl Size...:   0%|          | 0/25 [00:00<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  2.64 url/s]\n",
            "Dl Size...:   0%|          | 0/25 [00:00<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  2.64 url/s]\n",
            "Dl Size...:   0%|          | 0/29 [00:00<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  2.64 url/s]\n",
            "Dl Size...:   0%|          | 0/29 [00:00<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...:   0%|          | 0/1 [00:00<?, ? file/s]\u001b[A\u001b[A\n",
            "\n",
            "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  2.64 url/s]\n",
            "Dl Size...:   0%|          | 0/29 [00:00<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.64 url/s]\n",
            "Dl Size...:   0%|          | 0/29 [00:00<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.64 url/s]\n",
            "Dl Size...:   0%|          | 0/29 [00:00<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.64 url/s]\n",
            "Dl Size...:   0%|          | 0/29 [00:00<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 100%|██████████| 2/2 [00:00<00:00,  2.38 file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.64 url/s]\n",
            "Dl Size...:   3%|▎         | 1/29 [00:00<00:26,  1.05 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  50%|█████     | 2/4 [00:01<00:00,  2.64 url/s]\n",
            "Dl Size...:   7%|▋         | 2/29 [00:00<00:25,  1.05 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 100%|██████████| 2/2 [00:01<00:00,  2.38 file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:  50%|█████     | 2/4 [00:01<00:00,  2.64 url/s]\n",
            "Dl Size...:  10%|█         | 3/29 [00:01<00:17,  1.47 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  50%|█████     | 2/4 [00:01<00:00,  2.64 url/s]\n",
            "Dl Size...:  14%|█▍        | 4/29 [00:01<00:17,  1.47 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  50%|█████     | 2/4 [00:01<00:00,  2.64 url/s]\n",
            "Dl Size...:  17%|█▋        | 5/29 [00:01<00:16,  1.47 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 100%|██████████| 2/2 [00:01<00:00,  2.38 file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:  50%|█████     | 2/4 [00:01<00:00,  2.64 url/s]\n",
            "Dl Size...:  21%|██        | 6/29 [00:01<00:11,  2.03 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  50%|█████     | 2/4 [00:01<00:00,  2.64 url/s]\n",
            "Dl Size...:  24%|██▍       | 7/29 [00:01<00:10,  2.03 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  50%|█████     | 2/4 [00:01<00:00,  2.64 url/s]\n",
            "Dl Size...:  28%|██▊       | 8/29 [00:01<00:10,  2.03 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  50%|█████     | 2/4 [00:01<00:00,  2.64 url/s]\n",
            "Dl Size...:  31%|███       | 9/29 [00:01<00:09,  2.03 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.47 url/s]\n",
            "Dl Size...:  31%|███       | 9/29 [00:01<00:09,  2.03 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.47 url/s]\n",
            "Dl Size...:  31%|███       | 9/29 [00:01<00:09,  2.03 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...:  67%|██████▋   | 2/3 [00:01<00:00,  2.38 file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.47 url/s]\n",
            "Dl Size...:  34%|███▍      | 10/29 [00:01<00:06,  2.80 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.47 url/s]\n",
            "Dl Size...:  38%|███▊      | 11/29 [00:01<00:06,  2.80 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...:  67%|██████▋   | 2/3 [00:01<00:00,  2.38 file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.47 url/s]\n",
            "Dl Size...:  41%|████▏     | 12/29 [00:01<00:04,  3.67 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.47 url/s]\n",
            "Dl Size...:  45%|████▍     | 13/29 [00:01<00:04,  3.67 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...:  67%|██████▋   | 2/3 [00:01<00:00,  2.38 file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.47 url/s]\n",
            "Dl Size...:  48%|████▊     | 14/29 [00:01<00:03,  4.77 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.47 url/s]\n",
            "Dl Size...:  52%|█████▏    | 15/29 [00:01<00:02,  4.77 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...:  67%|██████▋   | 2/3 [00:01<00:00,  2.38 file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.47 url/s]\n",
            "Dl Size...:  55%|█████▌    | 16/29 [00:01<00:02,  5.85 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.47 url/s]\n",
            "Dl Size...:  59%|█████▊    | 17/29 [00:01<00:02,  5.85 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...:  67%|██████▋   | 2/3 [00:01<00:00,  2.38 file/s]\u001b[A\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.47 url/s]\n",
            "Dl Size...:  59%|█████▊    | 17/29 [00:01<00:02,  5.85 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 100%|██████████| 3/3 [00:01<00:00,  1.91 file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.47 url/s]\n",
            "Dl Size...:  62%|██████▏   | 18/29 [00:01<00:01,  6.83 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.47 url/s]\n",
            "Dl Size...:  66%|██████▌   | 19/29 [00:02<00:01,  6.83 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.47 url/s]\n",
            "Dl Size...:  69%|██████▉   | 20/29 [00:02<00:01,  6.83 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 100%|██████████| 3/3 [00:02<00:00,  1.91 file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.47 url/s]\n",
            "Dl Size...:  72%|███████▏  | 21/29 [00:02<00:00,  8.85 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.47 url/s]\n",
            "Dl Size...:  76%|███████▌  | 22/29 [00:02<00:00,  8.85 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.47 url/s]\n",
            "Dl Size...:  79%|███████▉  | 23/29 [00:02<00:00,  8.85 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 100%|██████████| 3/3 [00:02<00:00,  1.91 file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.47 url/s]\n",
            "Dl Size...:  83%|████████▎ | 24/29 [00:02<00:00, 10.84 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.47 url/s]\n",
            "Dl Size...:  86%|████████▌ | 25/29 [00:02<00:00, 10.84 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.47 url/s]\n",
            "Dl Size...:  90%|████████▉ | 26/29 [00:02<00:00, 10.84 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 100%|██████████| 3/3 [00:02<00:00,  1.91 file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.47 url/s]\n",
            "Dl Size...:  93%|█████████▎| 27/29 [00:02<00:00, 12.92 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.47 url/s]\n",
            "Dl Size...:  97%|█████████▋| 28/29 [00:02<00:00, 12.92 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  2.47 url/s]\n",
            "Dl Size...: 100%|██████████| 29/29 [00:02<00:00, 12.92 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  1.58 url/s]\n",
            "Dl Size...: 100%|██████████| 29/29 [00:02<00:00, 12.92 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  1.58 url/s]\n",
            "Dl Size...: 100%|██████████| 29/29 [00:02<00:00, 12.92 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...:  75%|███████▌  | 3/4 [00:02<00:00,  1.91 file/s]\u001b[A\u001b[A\n",
            "\n",
            "Dl Completed...: 100%|██████████| 4/4 [00:03<00:00,  1.58 url/s]\n",
            "Dl Size...: 100%|██████████| 29/29 [00:03<00:00, 12.92 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 100%|██████████| 4/4 [00:03<00:00,  1.40 file/s]\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "Dl Size...: 100%|██████████| 29/29 [00:03<00:00,  9.22 MiB/s]\u001b[A\n",
            "0 examples [00:00, ? examples/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000 examples [00:48, 1245.25 examples/s]\n",
            "Shuffling...:   0%|          | 0/10 [00:00<?, ? shard/s]\n",
            "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Reading...: 6000 examples [00:00, 215328.09 examples/s]\u001b[A\n",
            "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling...:  10%|█         | 1/10 [00:00<00:00,  9.57 shard/s]\n",
            "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Reading...: 6000 examples [00:00, 193785.99 examples/s]\u001b[A\n",
            "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling...:  20%|██        | 2/10 [00:00<00:00,  9.42 shard/s]\n",
            "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Reading...: 6000 examples [00:00, 197253.70 examples/s]\u001b[A\n",
            "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling...:  30%|███       | 3/10 [00:00<00:00,  9.10 shard/s]\n",
            "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Reading...: 6000 examples [00:00, 218646.93 examples/s]\u001b[A\n",
            "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling...:  40%|████      | 4/10 [00:00<00:00,  9.35 shard/s]\n",
            "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Reading...: 6000 examples [00:00, 240464.61 examples/s]\u001b[A\n",
            "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling...:  50%|█████     | 5/10 [00:00<00:00,  9.10 shard/s]\n",
            "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Reading...: 6000 examples [00:00, 187761.22 examples/s]\u001b[A\n",
            "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling...:  60%|██████    | 6/10 [00:00<00:00,  9.34 shard/s]\n",
            "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Reading...: 6000 examples [00:00, 168675.13 examples/s]\u001b[A\n",
            "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling...:  70%|███████   | 7/10 [00:00<00:00,  9.31 shard/s]\n",
            "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Reading...: 6000 examples [00:00, 170012.93 examples/s]\u001b[A\n",
            "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling...:  80%|████████  | 8/10 [00:00<00:00,  9.26 shard/s]\n",
            "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Reading...: 6000 examples [00:00, 169878.66 examples/s]\u001b[A\n",
            "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling...:  90%|█████████ | 9/10 [00:00<00:00,  9.04 shard/s]\n",
            "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Reading...: 6000 examples [00:00, 152187.18 examples/s]\u001b[A\n",
            "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling...: 100%|██████████| 10/10 [00:01<00:00,  9.09 shard/s]\n",
            "10000 examples [00:07, 1268.80 examples/s]\n",
            "Shuffling...:   0%|          | 0/1 [00:00<?, ? shard/s]\n",
            "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Reading...: 10000 examples [00:00, 275611.04 examples/s]\u001b[A\n",
            "Writing...:   0%|          | 0/10000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling...: 100%|██████████| 1/1 [00:00<00:00,  7.21 shard/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "KyNKqr6H9zw9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gpDm8yk-98wo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(images, labels):\n",
        "  images = tf.cast(images, tf.float32)\n",
        "  images /= 255\n",
        "  return images, labels\n",
        "\n",
        "\n",
        "training_dataset =  training_dataset.map(normalize)\n",
        "testing_dataset  =  testing_dataset.map(normalize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YYGOML7I-Vzp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10,  activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LcBvCdLU-rGF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J8axOgQC-wDP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "training_dataset = training_dataset.repeat().shuffle(metadata.splits['train'].num_examples).batch(BATCH_SIZE)\n",
        "testing_dataset = testing_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hM9w7RJ6_C2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "01793ac7-2643-4855-99a9-644b3c297ddc"
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "model.fit(training_dataset, epochs=10, steps_per_epoch=math.ceil(metadata.splits['train'].num_examples/BATCH_SIZE))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.3985 - acc: 0.8565\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.2569 - acc: 0.9055\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.2145 - acc: 0.9212\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.1821 - acc: 0.9330\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 0.1583 - acc: 0.9417\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.1329 - acc: 0.9509\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.1101 - acc: 0.9590\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0966 - acc: 0.9638\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0788 - acc: 0.9710\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0690 - acc: 0.9744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb7218f41d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "QA-H2-S0Gh53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "56e68fa2-a4d3-409a-fa4d-f371bfeadd0e"
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(testing_dataset, steps=math.ceil(metadata.splits['test'].num_examples/32))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 11ms/step - loss: 0.3252 - acc: 0.9161\n",
            "Accuracy on test dataset: 0.9161\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}